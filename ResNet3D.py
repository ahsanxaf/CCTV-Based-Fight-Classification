# -*- coding: utf-8 -*-
"""ResNet (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S-AfAJH536Pck9gYPRct-1IC6jxcaGNk
"""

import cv2 as cv
import numpy as np
import os
import imutils
import random
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore", category=np.VisibleDeprecationWarning)
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn import metrics

from keras.preprocessing.image import ImageDataGenerator
from keras import backend as K
import keras
from keras.models import Sequential, Model,load_model
#from keras.optimizers import SGD
from keras.callbacks import EarlyStopping,ModelCheckpoint
from google.colab.patches import cv2_imshow
from keras.layers import Input, Add, Dense, Activation, ZeroPadding3D, BatchNormalization, Flatten, Conv3D, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D,MaxPool3D
from keras.preprocessing import image
from keras.initializers import glorot_uniform
from tensorflow.keras.optimizers import Adam,SGD
from keras.models import *
from keras.layers import *
from keras.optimizers import *
from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler, EarlyStopping

from google.colab import drive
drive.mount('/content/drive')

#cd drive/My\Drive

import zipfile
import os

zip_ref = zipfile.ZipFile('/content/drive/MyDrive/fight-detection-surv-dataset-master.zip', 'r') #Opens the zip file in read mode
zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder
zip_ref.close()

directory = r'/tmp/fight-detection-surv-dataset-master'
CATEGORIES = ['fight', 'noFight']

data = []
labels = []
for category in CATEGORIES:
    folder = os.path.join(directory, category)
    label = CATEGORIES.index(category)
    print(folder)
    for frame in os.listdir(folder):
        frm_path = os.path.join(folder, frame)
        cap = cv.VideoCapture(frm_path)
        video = []
        while cap.isOpened():
            ret, frames = cap.read()
            if ret == True:
                video.append(frames)
            else:
                break
        if len(video) > 30:
          for i in range(len(video)):
              video[i] = cv.resize(video[i], (120, 120))
#              video[i] = cv.cvtColor(video[i], cv.COLOR_BGR2GRAY)
          rem = len(video) % 30
          video = video[int(rem/2): -(int(rem/2))]
          if len(video) % 2 != 0:
              video = video[1:]
          NumberOfSamples = int(len(video)/30)
          for i in range(NumberOfSamples):
              sample = np.array(video[i*30: ((i+1)*30)])
              data.append(sample)
              labels.append(category)

  
print ("dataset ",np.array(data).shape)

from sklearn import preprocessing

le = preprocessing.LabelEncoder()
le.fit(labels)
labels = le.transform(labels)

data = np.array(data)/255

image_shape = np.array(data[0]).shape

def identity_block(X, f, filters, stage, block):
   
    conv_name_base = 'res' + str(stage) + block + '_branch'
    bn_name_base = 'bn' + str(stage) + block + '_branch'
    F1, F2, F3 = filters

    X_shortcut = X
   
    X = Conv3D(filters=F1, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)
    X = BatchNormalization(axis=4, name=bn_name_base + '2a')(X)
    X = Activation('relu')(X)

    X = Conv3D(filters=F2, kernel_size=(1, f, f), strides=(1, 1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)
    X = BatchNormalization(axis=4, name=bn_name_base + '2b')(X)
    X = Activation('relu')(X)

    X = Conv3D(filters=F3, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)
    X = BatchNormalization(axis=4, name=bn_name_base + '2c')(X)

    X = Add()([X, X_shortcut])# SKIP Connection
    X = Activation('relu')(X)

    return X

def convolutional_block(X, f, filters, stage, block, s=2):
   
    conv_name_base = 'res' + str(stage) + block + '_branch'
    bn_name_base = 'bn' + str(stage) + block + '_branch'

    F1, F2, F3 = filters

    X_shortcut = X

    X = Conv3D(filters=F1, kernel_size=(1, 1, 1), strides=(1, s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)
    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)
    X = Activation('relu')(X)

    X = Conv3D(filters=F2, kernel_size=(1, f, f), strides=(1, 1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)
    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)
    X = Activation('relu')(X)

    X = Conv3D(filters=F3, kernel_size=(1, 1,1), strides=(1, 1,1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)
    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)

    X_shortcut = Conv3D(filters=F3, kernel_size=(1, 1, 1), strides=(1, s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)
    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)

    X = Add()([X, X_shortcut])
    X = Activation('relu')(X)

    return X

def ResNet50(input_shape=(30, 120, 120, 3)):

    X_input = Input(input_shape)

    X = ZeroPadding3D((1, 3, 3))(X_input)

    X = Conv3D(64, (3, 5, 5), strides=(1, 2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)
    X = BatchNormalization(axis=3, name='bn_conv1')(X)
    X = Activation('relu')(X)
    X = MaxPooling3D((3, 3, 3), strides=(1, 2, 2))(X)

    X = convolutional_block(X, f=5, filters=[64, 64, 256], stage=2, block='a', s=1)
    X = identity_block(X, 5, [64, 64, 256], stage=2, block='b')
    X = identity_block(X, 5, [64, 64, 256], stage=2, block='c')
    X = MaxPooling3D((3, 3, 3), strides=(2, 2, 2))(X)


    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)
    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')
    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')
    X = MaxPooling3D((3, 3, 3), strides=(2,2,2))(X)

    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)

    X = AveragePooling3D(pool_size=(1, 2, 2), padding='same')(X)
    
    model = Model(inputs=X_input, outputs=X, name='ResNet50')

    return model

base_model = ResNet50(input_shape=(30, 120, 120, 3))

headModel = base_model.output
headModel = Flatten()(headModel)
headModel=Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)
headModel=Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)
headModel = Dense( 1,activation='sigmoid', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)

model = Model(inputs=base_model.input, outputs=headModel)
model.summary()

model.compile(optimizer = 'adam' , loss = tf.keras.losses.BinaryCrossentropy(from_logits=True) , metrics = ['accuracy' ])
model.fit(data, labels, batch_size = 2,  epochs=50,verbose=1)

model.save('model.h5')

video = r'/tmp/fight-detection-surv-dataset-master/fight/fi001.mp4'
if len(video) > 30:
   for i in range(len(video)):
     video[i] = cv.resize(video[i], (120, 120))
     rem = len(video) % 30
     video = video[int(rem/2): -(int(rem/2))]
     if len(video) % 2 != 0:
       video = video[1:]

